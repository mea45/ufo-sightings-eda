{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5efc75-afce-492f-8141-479b22e9de15",
   "metadata": {},
   "source": [
    "# **UFO Sightings - Part 1: Preprocessing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b0a3b-a6b9-4710-a5ad-ac30f06c8ce6",
   "metadata": {},
   "source": [
    "## 1. Importing Data Set and Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e45a81-dca6-4eaf-ae2b-60ebd808d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html                                  # package used to convert text\n",
    "import numpy as np                           # linear algebra\n",
    "import os                                    # package used to set work directory\n",
    "import pandas as pd                          # package used to create dataframes\n",
    "import re                                    # regular expressions\n",
    "\n",
    "from datetime import datetime                # package used to convert string to datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3aead7-7d04-4d80-af44-e32b4f0d9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('scrubbed.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8262bc74-5577-4045-b0c6-f3fb40cc0967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80332 entries, 0 to 80331\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   datetime              80332 non-null  object \n",
      " 1   city                  80332 non-null  object \n",
      " 2   state                 74535 non-null  object \n",
      " 3   country               70662 non-null  object \n",
      " 4   shape                 78400 non-null  object \n",
      " 5   duration (seconds)    80332 non-null  object \n",
      " 6   duration (hours/min)  80332 non-null  object \n",
      " 7   comments              80317 non-null  object \n",
      " 8   date posted           80332 non-null  object \n",
      " 9   latitude              80332 non-null  object \n",
      " 10  longitude             80332 non-null  float64\n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bac493-37f7-42df-a5b1-98f19ec80737",
   "metadata": {},
   "source": [
    "The data set contains a decent amount of observations, 80,332 to be specific, and 11 columns. Apart from the column `longitude`, the columns are not assigned a data type. Before we assign data types, we will first do some further exploration. The columns `state`, `country`, `shape` and `comments` seem to have missing values which should be addressed as well. There are two different columns that contain the durations of the UFO sightings. All of these points will be addressed in the next section where we will be cleaning and preparing the data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441edea-e02b-486c-951f-2d38bf00217b",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7dedb-0652-43da-9cda-1852d11d1e5f",
   "metadata": {},
   "source": [
    "In the previous section, we've already noticed some things with the data. We will go through them one by one in this section. Whatever other issues we stumble on during the process will also be addressed. We'll copy the data set to a new variable so we can manipulate the data without losing the original raw data. We also print the first five rows to get a look of what the entries look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97870949-5f88-43bf-81fd-20e485baa5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           datetime                  city state country     shape  \\\n",
      "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
      "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
      "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
      "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
      "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
      "\n",
      "  duration (seconds) duration (hours/min)  \\\n",
      "0               2700           45 minutes   \n",
      "1               7200              1-2 hrs   \n",
      "2                 20           20 seconds   \n",
      "3                 20             1/2 hour   \n",
      "4                900           15 minutes   \n",
      "\n",
      "                                            comments date posted    latitude  \\\n",
      "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
      "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
      "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
      "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
      "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
      "\n",
      "   longitude   \n",
      "0  -97.941111  \n",
      "1  -98.581082  \n",
      "2   -2.916667  \n",
      "3  -96.645833  \n",
      "4 -157.803611  \n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "pd.set_option('display.max_columns', None)    # shows all columns\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe10a8-84fc-4d95-9f33-c68d6387d789",
   "metadata": {},
   "source": [
    "### 2.1 Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5963d3e-9f24-4bbf-86d4-d70b0b5b72e5",
   "metadata": {},
   "source": [
    "There are two columns that contain the coordinates of the UFO sightings. The `longitude` column's data type is `float64` which seems appropriate for the type of variable. We would ideally also want the `latitude` to be a float type date. First, the column name for the longitude should be renamed as it for some reason has an extra space at the end reading `longitude ` instead of `longitude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40962c67-4b79-4531-a033-3d3bd80c114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'longitude ': 'longitude'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aaa8ac-c4ea-48b8-b52b-656f6da4051c",
   "metadata": {},
   "source": [
    "When we try to convert the column `latitude`, it immediately returns a value error. One of the entries is not numerical. The recorded value is '33q.200088'. We look for this element in the column and print the corresponding column values to see if we can fix this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6093e68-0e78-4909-8500-07d874d7c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime                                                  5/22/1974 05:30\n",
      "city                                         mescalero indian reservation\n",
      "state                                                                  nm\n",
      "country                                                               NaN\n",
      "shape                                                           rectangle\n",
      "duration (seconds)                                                    180\n",
      "duration (hours/min)                                            two hours\n",
      "comments                Huge rectangular object emmitting intense whit...\n",
      "date posted                                                     4/18/2012\n",
      "latitude                                                       33q.200088\n",
      "longitude                                                     -105.624152\n",
      "Name: 43782, dtype: object\n"
     ]
    }
   ],
   "source": [
    "latitude_error_index = np.where(df == '33q.200088')[0].tolist()[0]\n",
    "print(df.iloc[latitude_error_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3495c53-14f1-41f8-8e30-723bac8558ae",
   "metadata": {},
   "source": [
    "We have the name of the location, namely, *Mescalero Indian Reservation*. A quick Google search gives us the following coordinates of this reservation (that nowadays is called *Mescalero Apache Reservation*): (33.157010803266594, -105.7795644741356). We can derive from this that the letter 'q' is accidentally added and we can just remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b74577-8f4e-4f5f-a34d-292152da9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[latitude_error_index, 'latitude'] = '33.200088'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d5998-c655-49f6-9a5b-6c6454a8a26a",
   "metadata": {},
   "source": [
    "Let's try again to convert the column to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d712c3c-4e87-4fc1-a7a4-f7d4b442581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "df = df.astype({'latitude':'float'})\n",
    "print(df.latitude.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6d377-fcf3-425f-be59-777679dd5075",
   "metadata": {},
   "source": [
    "The conversion is successful. Now both coordinates are float variables. The final thing we will check if there are missing values. From previous section (3.0) we already know that there are no empty cells. Also, the columns are completely numerical. However, we should check for zero values which may indicate missing values because a perfect zero value is highly unlikely as we are dealing with coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d7f58e-95a5-45ce-8696-13bc46c989fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero values in latitude: 0\n",
      "Number of zero values in longitude: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of zero values in latitude:', sum(df['latitude']==0))\n",
    "print('Number of zero values in longitude:', sum(df['longitude']==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150b96e-f996-4220-b6af-0a71cbe144ce",
   "metadata": {},
   "source": [
    "No issues here, which is great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ede337-1473-419a-9b74-7d7256da46bf",
   "metadata": {},
   "source": [
    "### 2.2 Date/time data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556dae5-f8d5-405b-b33e-f56e33fdf529",
   "metadata": {},
   "source": [
    "There are two variables that contain date/time data: `datetime`, which is the time at which the sighting took place, and `date posted`, which is the time at which the comment was recorded. We will start with `date posted` since this one is a little less complicated as it only contains the date, not the time. We first change the column name by replacing the space with an underscore for convenience. Then we convert the data type to `datetime64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d176b14e-3ad2-4a3b-b99e-fbc71245f832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'date posted': 'date_posted'})\n",
    "df['date_posted'] = [datetime.strptime(line, '%m/%d/%Y') for line in df['date_posted']]\n",
    "print(df.date_posted.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601525f-fabb-45ef-b82e-ec08cf8f0068",
   "metadata": {},
   "source": [
    "Now that we have converted `date_posted`, we move on to `datetime`. However, there is one issue with this column. The time is recorded in a 24-hour clock format. However, 12 a.m. (24h) is noted as '24:xx' while we need it to be '00:xx' to be able to convert the data type. Once that's fixed, we can do the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0fb83c-2b43-4cd9-8eb7-3b3d503ea4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "corrected_datetime = [line[:line.find('24:')] + '00:' + line[line.find('24:') + 3:] if line.find('24:') != -1 else line for line in df['datetime']]\n",
    "df['datetime'] = [datetime.strptime(line, '%m/%d/%Y %H:%M') for line in corrected_datetime]\n",
    "print(df.datetime.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d79ac-d091-460c-839e-46efe2791db5",
   "metadata": {},
   "source": [
    "Now both columns are succesfully converted into datetime variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e3aa6-e71b-4eba-8ea2-2df997a068d4",
   "metadata": {},
   "source": [
    "### 2.3 Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730753a-0e76-45b2-973e-8c249c47826d",
   "metadata": {},
   "source": [
    "As mentioned before, there are two columns containing the durations of the UFO sightings: `duration (seconds)` and `duration (hours/min)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313021af-1f8a-44a0-b25b-3b4332836b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2700\n",
      "1    7200\n",
      "2      20\n",
      "3      20\n",
      "4     900\n",
      "Name: duration (seconds), dtype: object\n",
      "0    45 minutes\n",
      "1       1-2 hrs\n",
      "2    20 seconds\n",
      "3      1/2 hour\n",
      "4    15 minutes\n",
      "Name: duration (hours/min), dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['duration (seconds)'].head())\n",
    "print(df['duration (hours/min)'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cade9-2c67-490a-a735-c7fb343bc534",
   "metadata": {},
   "source": [
    "`duration (hours/min)` is the textual recording of the duration. This seems to be the original raw data that someone (manually) converted into numerical notation in seconds. For time's sake, we will assume that this process is done properly. We ideally would want to solely use the `duration (seconds)` column and convert it to a float data type. However, when we try to convert the column, it returns a value error. A few entries have been somehow corrupted. What happened is that for a few entries the numerical part of the element is followed by a `. There are three elements this happend to: \n",
    "- 2`\n",
    "- 8`\n",
    "- 0.5`\n",
    "\n",
    "We look those elements up and fix them so they are completely numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c566f7ec-8f89-49b4-bbdb-f78c36d5402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_elements = [\"2`\", \"8`\", \"0.5`\"]\n",
    "for we in wrong_elements:\n",
    "    duration_error_index = np.where(df == we)[0].tolist()[0]\n",
    "    df.loc[duration_error_index, 'duration (seconds)'] = we[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e960a8c-5b67-433a-b34e-b9b05b655eb3",
   "metadata": {},
   "source": [
    "Now we can convert the column into a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d773a1cc-e0a7-4027-bf43-06483b1ccde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'duration (seconds)':'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3605eaa-5550-4ebf-8b71-1bb0b693bb64",
   "metadata": {},
   "source": [
    "Since we are not going to use the textual duration column and we can always access it from the raw data, we are going to remove this column and rename the numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef30b99-52df-4339-b287-99b0ad6afeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns='duration (hours/min)')\n",
    "df = df.rename(columns={'duration (seconds)': 'duration'})\n",
    "df = df.astype({'duration':'float'})\n",
    "print(df.duration.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a8fd7-4b22-420a-aa1b-2781d840026f",
   "metadata": {},
   "source": [
    "### 2.4 Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9095f2-1b20-40ab-8988-4cc50a7ddf88",
   "metadata": {},
   "source": [
    "This column contains the shape of the UFO that was claimed to be sighted. Earlier we noticed that there were missing values: 1,931 in total. Let's take a look at how this column looks like. We'll begin with listing the unique entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7693e727-d626-44e0-afcd-fa4897a6facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape\n",
       "light        16565\n",
       "triangle      7865\n",
       "circle        7608\n",
       "fireball      6208\n",
       "other         5649\n",
       "unknown       5584\n",
       "sphere        5387\n",
       "disk          5213\n",
       "oval          3733\n",
       "formation     2457\n",
       "cigar         2057\n",
       "changing      1962\n",
       "flash         1328\n",
       "rectangle     1297\n",
       "cylinder      1283\n",
       "diamond       1178\n",
       "chevron        952\n",
       "egg            759\n",
       "teardrop       750\n",
       "cone           316\n",
       "cross          233\n",
       "delta            7\n",
       "round            2\n",
       "crescent         2\n",
       "pyramid          1\n",
       "flare            1\n",
       "hexagon          1\n",
       "dome             1\n",
       "changed          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['shape'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdfbc1-e41c-41bf-a51a-5d60bce9ab63",
   "metadata": {},
   "source": [
    "There are 30 different unique entries including the missing values. There is one shape called 'unknown'. Since there are way too many missing values to do some text analysis on the comments without the guarantee that enough of them contain information on the shape of the alleged UFO, we will just assign the value *'unknown'* to the missing values. The subset of observations with an *'unknown'* shape is already much larger than the amount of missing values, so this should not mess up the proportions of the different subsets too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "749702ec-72e3-437e-8f66-4ce4b02c9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shape'] = [line if not pd.isna(line) else 'unknown' for line in df['shape']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee177fb-eb53-40dc-90d3-e01863633e95",
   "metadata": {},
   "source": [
    "### 2.5 Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb984ac-fa38-43ab-a607-b75a1d552f63",
   "metadata": {},
   "source": [
    "The column containing the comments has 15 missing values. We will replace these with empty strings. We will simultaneously deal with the html encoding that has been applied to the text (example *'&'* was saved in the csv file as *'\\&amp;'* and *\"'\"* as *'\\&#x27;'*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89f7d418-5f93-4d71-9c4d-f34f462d68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments'] = [html.unescape(line) if not pd.isna(line) else '' for line in df['comments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e5141-c93b-4997-8823-0ce387f2cade",
   "metadata": {},
   "source": [
    "This is all we will do to the comments. We will create a new column with the length of the comments which may be interested in the data analysis part of this project. The length of the comments will be the number of characters in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8048072f-4d32-496b-a658-f5b21fae8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments_length'] = [len(line) for line in df['comments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00352a0-5173-4b7f-ab49-dde35a6fd814",
   "metadata": {},
   "source": [
    "### 2.6 Location String Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79503e50-12da-4fa3-89ae-d42d21213727",
   "metadata": {},
   "source": [
    "Finally, we will explore the location data: `city`, `state` and `country`. The latter two have missing values. Let's look at the number of unique values each of these columns contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93df1ee0-a59c-4019-9cc6-c58b280ed6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80332 entries, 0 to 80331\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   datetime         80332 non-null  datetime64[ns]\n",
      " 1   city             80332 non-null  object        \n",
      " 2   state            74535 non-null  object        \n",
      " 3   country          70662 non-null  object        \n",
      " 4   shape            80332 non-null  object        \n",
      " 5   duration         80332 non-null  float64       \n",
      " 6   comments         80332 non-null  object        \n",
      " 7   date_posted      80332 non-null  datetime64[ns]\n",
      " 8   latitude         80332 non-null  float64       \n",
      " 9   longitude        80332 non-null  float64       \n",
      " 10  comments_length  80332 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(5)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4f1e66b-3f76-41b5-9c63-3318eec4f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for city: 19900\n",
      "Number of unique values for state: 68\n",
      "Number of unique values for country: 6\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique values for city:', len(pd.unique(df['city'])))\n",
    "print('Number of unique values for state:', len(pd.unique(df['state'])))\n",
    "print('Number of unique values for country:', len(pd.unique(df['country'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ea341-6a06-4dae-8905-f26d68d24196",
   "metadata": {},
   "source": [
    "It's interesting to see that there are only six unique values for `country`. Let's see which countries these are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c9236b9-4008-436c-87d0-2b0351258455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "us    65114\n",
      "ca     3000\n",
      "gb     1905\n",
      "au      538\n",
      "de      105\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145ad5c-3c32-4dca-b005-1e475a8c69d3",
   "metadata": {},
   "source": [
    "There are 9,669 missing values. About 65,000 sightings took place in the United States. The other 5,548 sightings have been reported to have happened in Canada, Great Britain, Australia and Germany. Since we have the coordinates of the sightings, we will not spend too much time on these three columns. We will fix the missing values issue and assign a string data type to the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f27033b6-4483-44aa-a218-7530668a01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = [line if not pd.isna(line) else '' for line in df['state']]\n",
    "df['country'] = [line if not pd.isna(line) else '' for line in df['country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba3300-45b1-4496-9ebe-2e223cb8ec6d",
   "metadata": {},
   "source": [
    "## 2.7 Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35922bf-c5ca-4c3d-a9fb-030b7a287db0",
   "metadata": {},
   "source": [
    "Finally, we will check for duplicates and remove them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "368ad801-62be-4d3a-a374-990b04a4a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e9236-fde0-41eb-8418-7006b7a9a1ba",
   "metadata": {},
   "source": [
    "There are two rows that have duplicates. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5d4662f-69d8-468d-9717-fc171739d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad7c6e-85c6-4645-88a7-b3dbe533ec2f",
   "metadata": {},
   "source": [
    "## 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa227e9-73f7-460f-86ef-ec18df8e41d1",
   "metadata": {},
   "source": [
    "We have converted `datetime` and `date posted` (renamed to `date_posted`) into datetime data types. We have dealt with the missing values in the columns `state`, `country`, `shape` and `comments`. The text numerical have been converted into float or integer elements. The column `duration (hours/min)` has been dropped as `duration (seconds)` (renamed to `duration`) would be more appropriate to work with. We added a column `comments_length` containing the length of the comments. Below, you find an overview of the data set properties. Finally, two rows that were duplicates were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a8fd15-6656-404d-a4b9-99a69c432264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80330 entries, 0 to 80331\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   datetime         80330 non-null  datetime64[ns]\n",
      " 1   city             80330 non-null  object        \n",
      " 2   state            80330 non-null  object        \n",
      " 3   country          80330 non-null  object        \n",
      " 4   shape            80330 non-null  object        \n",
      " 5   duration         80330 non-null  float64       \n",
      " 6   comments         80330 non-null  object        \n",
      " 7   date_posted      80330 non-null  datetime64[ns]\n",
      " 8   latitude         80330 non-null  float64       \n",
      " 9   longitude        80330 non-null  float64       \n",
      " 10  comments_length  80330 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9f4ca-c2c1-4921-bfd4-0df914c992c1",
   "metadata": {},
   "source": [
    "We export the preprocessed data into a csv file so we can work on it in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587f634e-a874-41e0-a100-778b7930b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
